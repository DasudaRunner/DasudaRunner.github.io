---
layout: post
title: "CUDA编程入门"
date: 2018-10-10
categories:
- CUDA
tag:
- CUDA
- 编程
---
感觉熟悉并行计算也是比较有竞争力的一项能力，且不说这个的应用场景还非常广泛，只要部署平台有显卡，只要有程序的地方，基本都可以考虑进行并行优化，可见它的应用还是听广泛的，并且现在支持cuda编程的语言也在增加，相信cuda将会是以后GPU编程的主要框架。


### GPU计算架构一览

简单的画一幅图来说明一下GPU的基本计算架构以及相关专有名词。

<img src="/assets/images/posts/cuda/cuda.jpg"> 

#### thread

也叫做SP，流处理器，是运行程序的最小单位

#### block

也叫做SM，流处理器簇，一组SP构成的集合，比如GTX 1070 8G的显卡上一个SM里面包含1024个SP，当前GPU硬件的发展也是在显卡上塞进越来越多的SM和SP

#### grid

这个其实还是block层面的划分，当一些block正在运行同一个程序时，这堆block可以被划分为一个grid，其实也可以理解为grid是真正在并行执行程序的单位（它的内部有大量属于不同block的thread在并行执行程序）

#### register

这个是寄存器文件，供SP去访问，储存了SP内部活跃的寄存器

#### local memory

供SP使用的内部存储空间

#### share memory

共享存储空间，是每个SM内部的SP共用一份，不同的SM有不同的share memory

#### global memory、constant memory、texture memory

global memory就是全局内存，共多个SM进行访问，constant memory、texture memory都是针对global memory建立的特殊视图，constant memory用于存储一些只读的数据，texture memory用来存储插值计算需要的数据。

### 未完待续