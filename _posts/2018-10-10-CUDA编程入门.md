---
layout: post
title: "CUDA编程入门"
date: 2018-10-10
categories:
- CUDA
tag:
- CUDA
- 编程
---
感觉熟悉并行计算也是比较有竞争力的一项能力，且不说这个的应用场景还非常广泛，只要部署平台有显卡，只要有程序的地方，基本都可以考虑进行并行优化，可见它的应用还是听广泛的，并且现在支持cuda编程的语言也在增加，相信cuda将会是以后GPU编程的主要框架。


### GPU计算架构一览

简单的画一幅图来说明一下GPU的基本计算架构以及相关专有名词。

<img src="/assets/images/posts/cuda/cuda.jpg"> 

#### thread

在硬件上对应一个SP（Streaming Processor），流处理器，是运行程序的最小单位，cuda程序的并行计算具体体现在大量的SP并行运行指令。

#### block

在硬件上对应SM（Streaming Multi-Processor），流处理器簇，程序中定义的block也是运行在SM上的，它里面包含了一组SP，具体数量视GPU的架构和型号而定，例如：GTX 1070 一个block最多可容纳1024个thread，共有15个SM，帕斯卡结构，表示每个SM最多包

#### grid

这个其实还是block层面的划分，当一些block正在运行同一个程序时，这堆block可以被划分为一个grid

**小结：**thread、block和grid是在软件层面的定义，在硬件的层面，实际执行的“机构”是SP和SM，而且在实际执行的时候，GPU的调度器也并不是具体去调度每个SP，而是让少量SP形成一个warp，调度器调度的最小单位为0.5个warp，一般的，GPU的warpSize为32，即每32个SP组成一组，当执行读取或者存储指令时，调度器会将以warp为单位统一执行，提高了效率

#### register

这个是寄存器文件，供SP去访问，储存了SP内部活跃的寄存器

#### local memory

供SP使用的内部存储空间

#### share memory

共享存储空间，是每个SM内部的SP共用一份，不同的SM有不同的share memory

#### global memory、constant memory、texture memory

global memory就是全局内存，共多个SM进行访问，constant memory、texture memory都是针对global memory建立的特殊视图，constant memory用于存储一些只读的数据，texture memory用来存储插值计算需要的数据。

**小结：**GPU上的存储器均为DRAM，这就说明连续存取数据是效率最高的方式

### 未完待续
