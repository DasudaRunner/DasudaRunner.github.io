---
layout: post
title: "Kaggle比赛kernel学习[小样本学习]"
date: 2018-12-07
categories:
- Kaggle
tag:
- Kaggle
- 深度学习
---

第一次参加kaggle比赛，发现kaggle参赛者们贡献的kernel真是神奇，方法多种多样，感觉自己的思路也别打通了，果然众人拾柴火焰高，一个难题竟然被各种各样的方式解决。但是也是深刻认识到，有些kaggle比赛，比的是硬件，而算法都差不多。

## Humpback Whale Identification
座头鲸识别，属于小样本分类方向，有专门的one-shot learning和few-shot learning领域的研究，这类问题特点是样本类别多，每类样本数量极少，在本比赛中，一共5004+1类座头鲸（训练集中有大量的图片为自然界未分类的座头鲸，这一类统称为'new\_whale'），其中数量最多的一类为'new\_whale'，其余有已知标签的类别数量最多在100张一下，大部分类别下只有一张图片，可见样本少，同时分布非常不平衡。

### [Whale Recognition Model with score 0.78563](https://www.kaggle.com/martinpiotte/whale-recognition-model-with-score-0-78563)

这是playground的座头鲸识别比赛的第一名，使用的方法是改进版孪生网络。之前也只了解过孪生网络，它是用来学习特征空间转换方法，将图像的像素信息投影到可度量的欧式空间或者其它成熟的可度量特征空间。类似还有三重损失网络triplet network等。

- 训练集处理
	- 去除训练集中重复的图片，方法是计算图片的感知哈希（Perceptual Hash ）值，当哈希值一样或者相差小于6比特位，并且图像有相同的尺寸、类型，同时归一化后的图像均方差只差小于阈值，则认为是相同的图像，经计算，作者大于除去了450+张重复图片。
	- 去除掉'new\_whale'类别。
	- 去除掉样本数只有1的类别。
	- 去除掉黑名单中的图像，这应该是作者人工筛选的，主要是一些不包含座头鲸尾巴的、一幅图片两个尾巴、图片模糊看不清的等等

- 网络架构
	- 特征提取部分，是仿照ResNet50设计的，将每层的输出通道减小，最终输出512维的向量，可以理解为网络将图像的特征映射进一个512维的特征空间。
	- 决策部分，作者设计了四种度量方式，加和、成绩、差值的绝对值、差平方，并让网络来自行学习每种度量方式的权重，最终决策部分输出的是一个0-1的值，当输入的两幅图片属于同一类别时，输出越接近1，反之接近0。

- 数据预处理
	- 灰度化
	- 随机翻转
	- 放射变换

- 训练batch选取
	- 首先保证了每幅图片作为正例和反例的比例是相同的，防止了一些图片经常被当做反例，使网络不能很好的学习到特征，作者也分析了这样做是为了让网络学习到鲸的特征，而不是记住图片（有点意思）。
	- 训练正例pairs的选择，首先按照顺序将所有类别作为pairs的其中一个，然后计算他们的[derangment](https://en.wikipedia.org/wiki/Derangement)顺序作为pairs中的另一个，这样保证了每个类别都被用了两次（顺序一次，derangment计算的顺序一次）。
	- 训练反例pairs的选择（前提，pairs中的两幅图片不是同一个类别），作者加入了主动学习的思想，每次训练中尽量给网络hard sample，作者的思路是，给出一个值为0-1的随机矩阵，称为得分矩阵，正例pairs（即相同类别互相间）的相似性置为10000（因为正例pairs不参与反例pairs的抽取过程，这里的10000只是象征性的大值），此后每个epoch评估一次（这里的评估是将训练集每一幅图片都与除自己外的所有图片进行计算得分-决策部分的输出值，所以输出的得分矩阵大小为数据集图像数量x数据集图像数量，可以看出来非常庞大），然后将输出的评估分数再叠加上一个0-1的随机矩阵，其中随机矩阵会乘一个系数，这个系数也是在训练过程中不断调节的，用来控制选取反例的随机程度，根据得分矩阵使用[线性分配算法](https://en.wikipedia.org/wiki/Assignment_problem)找出一个组合作为反例pairs，然后讲本次选取的反例pairs对应的得分矩阵中的得分置为10000，为什么这么做呢？是为了让网络每个epoch都接触到不同的反例，假想一下，如果训练集中有一批很难区分的样本，如果不进行这样的处理，那么每次使用线性分配算法得到的组合都包括它们（因为它们的得分很低），这样很多其他的反例样本就得不到训练。
	- 总结一下，我认为作者貌似貌似并不是在做主动学习，而是让网络每次都学习分类效果相对好的样本，因为对于反例来说，得分越接近0，说明网络对它们的区分度越好（因为反例pairs的真实标签就是0），那么对于区分度不好的pairs，得分应该是接近1，那么在得分矩阵中我们应该着重考虑那些得分接近1的反例pairs，但是作者使用的线性分配算法算法是寻找‘损失最小的组合’，所以最后找出来的恰好是当前网络表现最好的一个组合，但是由于作者在得分矩阵上又叠加了一个随机矩阵来调控选取的hard samples的程度，总之作者的思路还是比较好的，至少对于我来说受益匪浅。

- 训练耗时部分
	- 每过几个epoch，需要对训练集的所有图片计算得分，从而选取合适的hard sample进行训练。
	- 线性分配算法随着矩阵的大小增加，时间复杂度指数增加，作者也只是近似得到了反例pairs组合。
	- 在最后的提交部分，需要计算每个测试样本和所有训练样本的得分。
	- 训练网络，作者大概用了两天训练模型（GTX1080 i7-8700）
	- 总之，没有好的硬件平台，好多比赛根本没精力去做。